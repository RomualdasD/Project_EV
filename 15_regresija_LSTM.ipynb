{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM neuroninio tinklo modelis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kodas parašytas su https://colab.research.google.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "\n",
    "# Duomenų nuskaitymas\n",
    "data = pd.read_csv('data_visi_v2.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    KIEKIS  PIRM_REG_METAI_LT  PIRM_REG_MEN_LT\n",
    "# 0      87               2001                1\n",
    "# 1     267               2001                2\n",
    "# 2     371               2001                3\n",
    "# 3     406               2001                4\n",
    "# 4     456               2001                5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizuojame duomenis\n",
    "# Normalizuojame duomenis su MinMaxScaler, kad visos reikšmės būtų intervale nuo 0 iki 1. \n",
    "# Tai padeda modelio mokymosi efektyvumui ir greičiui.\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Sekų kūrimas \n",
    "seq_length = 110\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "# Sukuriame ciklą, kuris prasideda nuo seq_length ir eina iki scaled_data pabaigos.\n",
    "for i in range(seq_length, len(scaled_data)):\n",
    "    x_data.append(scaled_data[i-seq_length:i])\n",
    "    y_data.append(scaled_data[i, data.columns.get_loc('KIEKIS')])\n",
    "\n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)\n",
    "\n",
    "# Shuffle # Sumaišome duomenis\n",
    "indices = np.arange(x_data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "x_data = x_data[indices]\n",
    "y_data = y_data[indices]\n",
    "\n",
    "# Padalijame į treniravimo ir testavimo rinkinius\n",
    "train_size = int(len(x_data) * 0.8)\n",
    "x_train, x_test = x_data[:train_size], x_data[train_size:]\n",
    "y_train, y_test = y_data[:train_size], y_data[train_size:]\n",
    "\n",
    "# Modelio kūrimas\n",
    "model = Sequential([\n",
    "    Input(shape=(seq_length, x_data.shape[2])),\n",
    "    LSTM(110, return_sequences=True),\n",
    "    LSTM(110, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(75, return_sequences=False),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Modelio kompiliavimas\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Modelio mokymas\n",
    "history = model.fit(x_train, y_train, epochs=40, batch_size=32, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch 1/40\n",
    "# 5/5 [==============================] - 12s 667ms/step - loss: 0.1797 - mae: 0.3621 - val_loss: 0.0786 - val_mae: 0.2644\n",
    "# Epoch 2/40\n",
    "# 5/5 [==============================] - 2s 338ms/step - loss: 0.0465 - mae: 0.1792 - val_loss: 0.0434 - val_mae: 0.1705\n",
    "# Epoch 3/40\n",
    "# 5/5 [==============================] - 2s 329ms/step - loss: 0.0322 - mae: 0.1414 - val_loss: 0.0118 - val_mae: 0.0890\n",
    "# Epoch 4/40\n",
    "# 5/5 [==============================] - 2s 335ms/step - loss: 0.0182 - mae: 0.1129 - val_loss: 0.0103 - val_mae: 0.0772\n",
    "# Epoch 5/40\n",
    "# 5/5 [==============================] - 2s 543ms/step - loss: 0.0131 - mae: 0.0928 - val_loss: 0.0117 - val_mae: 0.0809\n",
    "# Epoch 6/40\n",
    "# 5/5 [==============================] - 3s 496ms/step - loss: 0.0118 - mae: 0.0865 - val_loss: 0.0090 - val_mae: 0.0766\n",
    "# Epoch 7/40\n",
    "# 5/5 [==============================] - 2s 344ms/step - loss: 0.0124 - mae: 0.0866 - val_loss: 0.0092 - val_mae: 0.0749\n",
    "# Epoch 8/40\n",
    "# 5/5 [==============================] - 2s 327ms/step - loss: 0.0112 - mae: 0.0832 - val_loss: 0.0085 - val_mae: 0.0726\n",
    "# Epoch 9/40\n",
    "# 5/5 [==============================] - 2s 334ms/step - loss: 0.0111 - mae: 0.0834 - val_loss: 0.0079 - val_mae: 0.0694\n",
    "# Epoch 10/40\n",
    "# 5/5 [==============================] - 2s 327ms/step - loss: 0.0114 - mae: 0.0822 - val_loss: 0.0092 - val_mae: 0.0749\n",
    "# Epoch 11/40\n",
    "# 5/5 [==============================] - 2s 330ms/step - loss: 0.0132 - mae: 0.0923 - val_loss: 0.0078 - val_mae: 0.0686\n",
    "# Epoch 12/40\n",
    "# 5/5 [==============================] - 2s 445ms/step - loss: 0.0116 - mae: 0.0820 - val_loss: 0.0082 - val_mae: 0.0707\n",
    "# Epoch 13/40\n",
    "# 5/5 [==============================] - 3s 519ms/step - loss: 0.0116 - mae: 0.0863 - val_loss: 0.0085 - val_mae: 0.0721\n",
    "# Epoch 14/40\n",
    "# 5/5 [==============================] - 2s 330ms/step - loss: 0.0109 - mae: 0.0828 - val_loss: 0.0079 - val_mae: 0.0696\n",
    "# Epoch 15/40\n",
    "# 5/5 [==============================] - 2s 320ms/step - loss: 0.0112 - mae: 0.0841 - val_loss: 0.0079 - val_mae: 0.0692\n",
    "# Epoch 16/40\n",
    "# 5/5 [==============================] - 2s 332ms/step - loss: 0.0117 - mae: 0.0833 - val_loss: 0.0079 - val_mae: 0.0694\n",
    "# Epoch 17/40\n",
    "# 5/5 [==============================] - 2s 333ms/step - loss: 0.0143 - mae: 0.0958 - val_loss: 0.0084 - val_mae: 0.0717\n",
    "# Epoch 18/40\n",
    "# 5/5 [==============================] - 2s 333ms/step - loss: 0.0138 - mae: 0.0903 - val_loss: 0.0078 - val_mae: 0.0688\n",
    "# Epoch 19/40\n",
    "# 5/5 [==============================] - 2s 386ms/step - loss: 0.0114 - mae: 0.0850 - val_loss: 0.0107 - val_mae: 0.0779\n",
    "# Epoch 20/40\n",
    "# 5/5 [==============================] - 3s 581ms/step - loss: 0.0120 - mae: 0.0857 - val_loss: 0.0080 - val_mae: 0.0707\n",
    "# Epoch 21/40\n",
    "# 5/5 [==============================] - 2s 334ms/step - loss: 0.0107 - mae: 0.0823 - val_loss: 0.0087 - val_mae: 0.0728\n",
    "# Epoch 22/40\n",
    "# 5/5 [==============================] - 2s 334ms/step - loss: 0.0120 - mae: 0.0855 - val_loss: 0.0079 - val_mae: 0.0693\n",
    "# Epoch 23/40\n",
    "# 5/5 [==============================] - 2s 335ms/step - loss: 0.0122 - mae: 0.0878 - val_loss: 0.0087 - val_mae: 0.0723\n",
    "# Epoch 24/40\n",
    "# 5/5 [==============================] - 2s 329ms/step - loss: 0.0109 - mae: 0.0818 - val_loss: 0.0080 - val_mae: 0.0708\n",
    "# Epoch 25/40\n",
    "# 5/5 [==============================] - 2s 337ms/step - loss: 0.0112 - mae: 0.0848 - val_loss: 0.0110 - val_mae: 0.0789\n",
    "# Epoch 26/40\n",
    "# 5/5 [==============================] - 2s 333ms/step - loss: 0.0109 - mae: 0.0840 - val_loss: 0.0090 - val_mae: 0.0775\n",
    "# Epoch 27/40\n",
    "# 5/5 [==============================] - 3s 578ms/step - loss: 0.0124 - mae: 0.0858 - val_loss: 0.0103 - val_mae: 0.0761\n",
    "# Epoch 28/40\n",
    "# 5/5 [==============================] - 2s 328ms/step - loss: 0.0116 - mae: 0.0853 - val_loss: 0.0078 - val_mae: 0.0703\n",
    "# Epoch 29/40\n",
    "# 5/5 [==============================] - 2s 328ms/step - loss: 0.0124 - mae: 0.0838 - val_loss: 0.0083 - val_mae: 0.0707\n",
    "# Epoch 30/40\n",
    "# 5/5 [==============================] - 2s 372ms/step - loss: 0.0131 - mae: 0.0901 - val_loss: 0.0087 - val_mae: 0.0720\n",
    "# Epoch 31/40\n",
    "# 5/5 [==============================] - 2s 336ms/step - loss: 0.0114 - mae: 0.0823 - val_loss: 0.0084 - val_mae: 0.0743\n",
    "# Epoch 32/40\n",
    "# 5/5 [==============================] - 2s 326ms/step - loss: 0.0109 - mae: 0.0814 - val_loss: 0.0113 - val_mae: 0.0791\n",
    "# Epoch 33/40\n",
    "# 5/5 [==============================] - 2s 327ms/step - loss: 0.0117 - mae: 0.0853 - val_loss: 0.0075 - val_mae: 0.0669\n",
    "# Epoch 34/40\n",
    "# 5/5 [==============================] - 3s 587ms/step - loss: 0.0101 - mae: 0.0789 - val_loss: 0.0082 - val_mae: 0.0701\n",
    "# Epoch 35/40\n",
    "# 5/5 [==============================] - 2s 448ms/step - loss: 0.0109 - mae: 0.0827 - val_loss: 0.0076 - val_mae: 0.0670\n",
    "# Epoch 36/40\n",
    "# 5/5 [==============================] - 2s 328ms/step - loss: 0.0101 - mae: 0.0773 - val_loss: 0.0073 - val_mae: 0.0665\n",
    "# Epoch 37/40\n",
    "# 5/5 [==============================] - 2s 341ms/step - loss: 0.0100 - mae: 0.0779 - val_loss: 0.0083 - val_mae: 0.0718\n",
    "# Epoch 38/40\n",
    "# 5/5 [==============================] - 2s 333ms/step - loss: 0.0102 - mae: 0.0809 - val_loss: 0.0074 - val_mae: 0.0662\n",
    "# Epoch 39/40\n",
    "# 5/5 [==============================] - 2s 335ms/step - loss: 0.0103 - mae: 0.0791 - val_loss: 0.0075 - val_mae: 0.0668\n",
    "# Epoch 40/40\n",
    "# 5/5 [==============================] - 2s 336ms/step - loss: 0.0105 - mae: 0.0811 - val_loss: 0.0073 - val_mae: 0.0659"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Modelio vertinimas\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test MAE:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loss: 0.007325547281652689\n",
    "# Test MAE: 0.06591007113456726"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prognozės funkcija\n",
    "def predict_volume_for_test_data(model, x_test, scaler):\n",
    "    predictions = model.predict(x_test)\n",
    "    reshaped_predictions = predictions.reshape(-1, 1)\n",
    "    \n",
    "    dummy_array = np.zeros((reshaped_predictions.shape[0], scaler.n_features_in_))\n",
    "    dummy_array[:, data.columns.get_loc('KIEKIS')] = reshaped_predictions.flatten()\n",
    "    \n",
    "    original_scale_predictions = scaler.inverse_transform(dummy_array)\n",
    "    return original_scale_predictions[:, data.columns.get_loc('KIEKIS')]\n",
    "\n",
    "# Prognozavimas testavimo rinkiniui\n",
    "predicted_volume = predict_volume_for_test_data(model, x_test, scaler)\n",
    "\n",
    "# Tikrasis KIEKIS \n",
    "reshaped_true_volume = y_test.reshape(-1, 1)\n",
    "dummy_array_true = np.zeros((reshaped_true_volume.shape[0], scaler.n_features_in_))\n",
    "dummy_array_true[:, data.columns.get_loc('KIEKIS')] = reshaped_true_volume.flatten()\n",
    "original_scale_true_volume = scaler.inverse_transform(dummy_array_true)[:, data.columns.get_loc('KIEKIS')]\n",
    "\n",
    "# Nustatome tikslumo ribą\n",
    "threshold = 1.0\n",
    "\n",
    "# Apskaičiuojame procentinį tikslumą\n",
    "accuracy = np.mean(np.abs(1-abs(predicted_volume - original_scale_true_volume)/original_scale_true_volume )) * 100\n",
    "\n",
    "print(f'Accuracy within {threshold} unit(s): {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy within 1.0 unit(s): 89.10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parodome keletą prognozių ir tikrų reikšmių\n",
    "for i in range(10):\n",
    "    print(f'Predicted: {round(predicted_volume[i])}, True: {round(original_scale_true_volume[i])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predicted: 13690, True: 12929\n",
    "# Predicted: 8278, True: 9973\n",
    "# Predicted: 7737, True: 6991\n",
    "# Predicted: 13717, True: 13822\n",
    "# Predicted: 5993, True: 7260\n",
    "# Predicted: 11880, True: 12467\n",
    "# Predicted: 15038, True: 17289\n",
    "# Predicted: 11901, True: 10445\n",
    "# Predicted: 14706, True: 16822\n",
    "# Predicted: 11838, True: 11940"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mokymosi istorijos atvaizdavimas\n",
    "plt.plot(history.history['mae'])\n",
    "plt.plot(history.history['val_mae'])\n",
    "plt.title('Model MAE')\n",
    "plt.ylabel('MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='pic1.png' style='width:600px; float: left' > </img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='pic2.png' style='width:600px; float: left' > </img>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
